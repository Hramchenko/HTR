{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HTRTrainCNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hramchenko/HTR/blob/master/HTRTrainCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "uL5QRz_WMkMF",
        "colab_type": "code",
        "outputId": "df025e6a-cf80-4db1-f025-53d5dc272917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Device \" + torch.cuda.get_device_name(0))\n",
        "device = torch.device(\"cuda:0\")\n",
        "#device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device Tesla K80\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j5M_rV-VMqso",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "\n",
        "image_width = 1000\n",
        "image_height = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sqHNfBMaLYmd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from xml.dom import minidom\n",
        "import matplotlib.pyplot as plt\n",
        "from math import floor\n",
        "from random import random\n",
        "import scipy as sp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kVeBVZEgMtb2",
        "colab_type": "code",
        "outputId": "0d70d05f-b7c6-42a4-c286-cf7a32da4346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"./HTR/\")\n",
        "from IAMWords import IAMWords\n",
        "\n",
        "\n",
        "pad_length=-1\n",
        "train_set = IAMWords(\"train\", \"./IAM/\", batch_size=batch_size, line_height=image_height, line_width=image_width, scale=1, pad_length=pad_length, rand_x=7)\n",
        "test_set = IAMWords(\"test\", \"./IAM/\", batch_size=batch_size, line_height=image_height, line_width=image_width, scale=1, pad_length=pad_length, rand_x=7)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading ./IAM/words.train.pkl...\n",
            "Reading finished\n",
            "Reading ./IAM/words.test.pkl...\n",
            "Reading finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aPROjYtaLvLS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from ArtificialHandwritting import ArtificialHandwritting\n",
        "artificial_data = ArtificialHandwritting(batch_size, \"./MyLetters/\", 1.0, image_width, image_height, train_set.encode_word)\n",
        "data, target = artificial_data.make_random_batch(3, 400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wceUSjfAWM1v",
        "colab_type": "code",
        "outputId": "c8d9713d-541e-4125-c23d-51be104c6cf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(data[0], cmap=\"gray\")\n",
        "plt.show()\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAABmCAYAAAApmv2XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 200, 1000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "K2fWx6tuK-4m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from IPython.core.debugger import set_trace\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FOlJkOzNgngX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from Layers import *\n",
        "from HTREncoder import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tNCy7E6BNI1t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch = train_set.make_batch(use_binarization=False)\n",
        "data, target = batch\n",
        "target = target.to(device)\n",
        "data = data/255.0\n",
        "data = data.unsqueeze(1).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "68VQiNESFKjm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder = HTREncoder().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3fvJufA-1d9O",
        "colab_type": "code",
        "outputId": "febfc1b2-e4e1-4afd-d760-856ef384c132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "c = encoder(data)\n",
        "c.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 64, 122])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "KyHlpeQ1WuoI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FCDecoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FCDecoder, self).__init__()\n",
        "    encoded_width = 122\n",
        "    encoded_height = 64\n",
        "    encoded_size = encoded_width*encoded_height\n",
        "    symbols_count = len(train_set.codes)\n",
        "    from math import floor\n",
        "    self.fc = FullyConnectedX([encoded_size, floor(encoded_size*0.7)], activation_fn=nn.LeakyReLU(0.2), last_fn=nn.LeakyReLU(0.2))\n",
        "    self.fc2 = FullyConnectedX([floor(encoded_size*0.7), floor(encoded_size*0.3), symbols_count], activation_fn=nn.LeakyReLU(0.2), last_fn=nn.Tanh())\n",
        "    self.bn = nn.BatchNorm1d(floor(encoded_size*0.7))\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.fc(x)\n",
        "    x = self.bn(x)\n",
        "    x = self.fc2(x)\n",
        "    x = F.log_softmax(x, dim=1)\n",
        "    return x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2P3eeqqEeEqp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_fc = FCDecoder().to(device)\n",
        "cnn_optimizer = optim.Adam(encoder.parameters(), lr=1e-4, weight_decay=0.00005)\n",
        "fc_optimizer = optim.Adam(encoder_fc.parameters(), lr=1e-4, weight_decay=0.00005)\n",
        "criterion = nn.NLLLoss()\n",
        "randx = 900"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FTSmnINja6Q-",
        "colab_type": "code",
        "outputId": "008693f5-2196-4b48-e401-5268ad8bb76a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2129
        }
      },
      "cell_type": "code",
      "source": [
        "recognition_result = torch.LongTensor(batch_size, 1).to(device)\n",
        "\n",
        "for i in range(0, 2000):\n",
        "    data, target = artificial_data.make_random_batch(1, randx)\n",
        "    data = data.unsqueeze(1).to(device)\n",
        "    target = target.to(device)\n",
        "    cnn_optimizer.zero_grad()\n",
        "    fc_optimizer.zero_grad()\n",
        "    enc = encoder(data)\n",
        "    enc = enc.flatten(start_dim=1)\n",
        "    symb = encoder_fc(enc)\n",
        "    loss = criterion(symb, target[:, 0])\n",
        "    if i % 50 == 0:\n",
        "      recognition_result[:,0] = symb.topk(1, dim=1)[1].flatten().detach()\n",
        "      for i in range(0, 5):\n",
        "        t = test_set.decode_word(target[i,:])\n",
        "        r = test_set.decode_word(recognition_result[i,:])\n",
        "        print(t + \"->\" + r)\n",
        "      print(loss.item())\n",
        "    loss.backward()\n",
        "    cnn_optimizer.step()\n",
        "    fc_optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f->q\n",
            "q->q\n",
            "a->a\n",
            "r->r\n",
            "b->b\n",
            "2.6310861110687256\n",
            "h->h\n",
            "m->m\n",
            "h->u\n",
            "e->e\n",
            "b->b\n",
            "2.622636079788208\n",
            "g->g\n",
            "z->z\n",
            "v->y\n",
            "k->k\n",
            "l->t\n",
            "2.6252410411834717\n",
            "m->w\n",
            "m->m\n",
            "w->h\n",
            "k->h\n",
            "z->z\n",
            "2.629223108291626\n",
            "h->h\n",
            "q->q\n",
            "w->h\n",
            "f->f\n",
            "y->w\n",
            "2.6085665225982666\n",
            "h->u\n",
            "j->j\n",
            "c->e\n",
            "l->l\n",
            "b->b\n",
            "2.6162166595458984\n",
            "g->g\n",
            "v->v\n",
            "g->g\n",
            "c->e\n",
            "d->d\n",
            "2.5939812660217285\n",
            "d->d\n",
            "x->s\n",
            "p->p\n",
            "h->h\n",
            "z->z\n",
            "2.598590612411499\n",
            "g->d\n",
            "d->d\n",
            "k->h\n",
            "k->h\n",
            "o->o\n",
            "2.6026787757873535\n",
            "w->w\n",
            "q->d\n",
            "r->r\n",
            "c->e\n",
            "u->h\n",
            "2.5790352821350098\n",
            "p->g\n",
            "h->h\n",
            "q->q\n",
            "z->z\n",
            "v->v\n",
            "2.597132921218872\n",
            "z->z\n",
            "f->l\n",
            "h->h\n",
            "z->z\n",
            "h->h\n",
            "2.553447961807251\n",
            "t->l\n",
            "p->p\n",
            "p->p\n",
            "z->z\n",
            "v->v\n",
            "2.541186571121216\n",
            "e->e\n",
            "b->b\n",
            "x->x\n",
            "a->a\n",
            "k->h\n",
            "2.5517826080322266\n",
            "c->c\n",
            "a->a\n",
            "w->w\n",
            "p->p\n",
            "k->h\n",
            "2.579864501953125\n",
            "e->e\n",
            "g->g\n",
            "o->o\n",
            "h->h\n",
            "x->x\n",
            "2.5378713607788086\n",
            "i->i\n",
            "i->i\n",
            "l->l\n",
            "j->j\n",
            "i->i\n",
            "2.5448856353759766\n",
            "k->k\n",
            "n->x\n",
            "q->q\n",
            "o->o\n",
            "c->c\n",
            "2.5445191860198975\n",
            "i->i\n",
            "f->f\n",
            "g->g\n",
            "h->h\n",
            "r->s\n",
            "2.540536403656006\n",
            "c->e\n",
            "w->w\n",
            "w->w\n",
            "w->h\n",
            "v->y\n",
            "2.5518453121185303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "esw2RB0GmbRL",
        "colab_type": "code",
        "outputId": "43731030-65f6-4fe2-aadd-85581f52c8a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def save_cnn(file_name):\n",
        "  state_dict = {\n",
        "        \"encoder\": encoder.state_dict()\n",
        "      }\n",
        "  torch.save(state_dict, file_name)\n",
        "  print(\"Network saved: %s\" %file_name)\n",
        "save_cnn(\"/gdrive/My Drive/cnn.tar\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network saved: /gdrive/My Drive/cnn.tar\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}